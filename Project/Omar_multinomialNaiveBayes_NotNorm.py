# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Awm0wKDMsZMpa1sfnDwTXZz02EB6YOXu
"""

import pandas as pd
from sklearn import linear_model
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Normalizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import numpy as np

#Mounting Our Drive On Cloab
from google.colab import drive
drive.mount('/content/drive')

#uploading test and train files from google drive
train = pd.read_csv('/content/drive/MyDrive/omartrain.csv')
test = pd.read_csv('/content/drive/MyDrive/omartest.csv')
#Using variable for labels
y = train.Cover_Type

#For functions
X = train.drop('Cover_Type', axis=1)

#Splitting The Data y 20% and 80% test train
t_train, t_test, y_train, y_test = train_test_split(X, y,test_size=0.2)

#Continuing wothout data normalization


# Applying scikit multiclass Multinomial Naive Bayes Algo
mnb = MultinomialNB()
mnb.fit(t_train, y_train)
Y_pred = mnb.predict(t_test)
acc_mnb = round(mnb.score(t_train, y_train) * 100, 2)
print("Normalized Multinomial Naive Bayes accuracy =",round(acc_mnb,2,), "%")
print(Y_pred.shape)
#Exporting columns from dataframe
submission = pd.DataFrame({
        "Id": test["Id"],
        "Cover_Type": Y_pred
    })
#Making a file converting to csv
submission.to_csv('Omar_multinomialNaiveBayes_NotNorm.csv', index=False)